
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>3.3.8 实现动态模块导入 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-prism/prism-solarizedlight.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="9.框架完善--实现请求去重.html" />
    
    
    <link rel="prev" href="7.框架完善--实现多个中间件.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    python爬虫
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="../../爬虫阶段课程介绍/爬虫技术概述.html">
            
                <a href="../../爬虫阶段课程介绍/爬虫技术概述.html">
            
                    
                    1.爬虫技术概述
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../爬虫入门/">
            
                <a href="../../爬虫入门/">
            
                    
                    1 爬虫入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../../爬虫入门/1.爬虫的基础知识/">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/">
            
                    
                    1.1 爬虫的基础知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="../../爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
            
                    
                    1.1.1 爬虫的定义和使用场景
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="../../爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
            
                    
                    1.1.2 爬虫的分类和爬虫的流程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="../../爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
            
                    
                    1.1.3 http和https的复习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="../../爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
            
                    
                    1.1.4 字符串相关的复习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.5" data-path="../../爬虫入门/1.爬虫的基础知识/5.小结.html">
            
                <a href="../../爬虫入门/1.爬虫的基础知识/5.小结.html">
            
                    
                    1.1.5 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../../爬虫入门/2.requests模块的使用/">
            
                <a href="../../爬虫入门/2.requests模块的使用/">
            
                    
                    1.2 请求的发送方法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="../../爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
            
                    
                    1.2.1 requests模块的基本使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="../../爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
            
                    
                    1.2.2 requests模块的深入使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="../../爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
            
                    
                    1.2.3 requests模块处理cookie
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="../../爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
            
                    
                    1.2.4 requests的其他方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="../../爬虫入门/2.requests模块的使用/5.urllib的介绍.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/5.urllib的介绍.html">
            
                    
                    1.2.5 urllib的介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.6" data-path="../../爬虫入门/2.requests模块的使用/6小结.html">
            
                <a href="../../爬虫入门/2.requests模块的使用/6小结.html">
            
                    
                    1.2.6 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../../爬虫入门/3.数据提取方法/">
            
                <a href="../../爬虫入门/3.数据提取方法/">
            
                    
                    1.3 数据提取方法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="../../爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
            
                <a href="../../爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
            
                    
                    1.3.1 数据提取的概念和数据分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="../../爬虫入门/3.数据提取方法/2.json字符串的数据提取.html">
            
                <a href="../../爬虫入门/3.数据提取方法/2.json字符串的数据提取.html">
            
                    
                    1.3.2 数据提取之json
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="../../爬虫入门/3.数据提取方法/3.数据提取之正则.html">
            
                <a href="../../爬虫入门/3.数据提取方法/3.数据提取之正则.html">
            
                    
                    1.3.3 数据提取之正则
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="../../爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
            
                <a href="../../爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
            
                    
                    1.3.4 数据提取之xpath
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.5" data-path="../../爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
            
                <a href="../../爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
            
                    
                    1.3.5 数据提取之lxml
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.6" data-path="../../爬虫入门/3.数据提取方法/6.beautifulsoup的学习.html">
            
                <a href="../../爬虫入门/3.数据提取方法/6.beautifulsoup的学习.html">
            
                    
                    1.3.6 数据提取之beautifulsoup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.7" data-path="../../爬虫入门/3.数据提取方法/7.小结.html">
            
                <a href="../../爬虫入门/3.数据提取方法/7.小结.html">
            
                    
                    1.3.7 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../爬虫提高/">
            
                <a href="../../爬虫提高/">
            
                    
                    2 爬虫提高
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../爬虫提高/1.高性能爬虫/">
            
                <a href="../../爬虫提高/1.高性能爬虫/">
            
                    
                    2.1高性能爬虫
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="../../爬虫提高/1.高性能爬虫/1.单线程爬虫.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/1.单线程爬虫.html">
            
                    
                    2.1.1 单线程爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="../../爬虫提高/1.高性能爬虫/2.多线程爬虫.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/2.多线程爬虫.html">
            
                    
                    2.1.2 多线程爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="../../爬虫提高/1.高性能爬虫/3.多进程爬虫.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/3.多进程爬虫.html">
            
                    
                    2.1.3 多进程爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="../../爬虫提高/1.高性能爬虫/4.线程池爬虫.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/4.线程池爬虫.html">
            
                    
                    2.1.4 线程池爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="../../爬虫提高/1.高性能爬虫/5.协程池爬虫.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/5.协程池爬虫.html">
            
                    
                    2.1.5 协程池爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.6" data-path="../../爬虫提高/1.高性能爬虫/6.小结.html">
            
                <a href="../../爬虫提高/1.高性能爬虫/6.小结.html">
            
                    
                    2.1.6 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../爬虫提高/2.selenium/">
            
                <a href="../../爬虫提高/2.selenium/">
            
                    
                    2.2 selenium
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="../../爬虫提高/2.selenium/1.无头浏览器的介绍.html">
            
                <a href="../../爬虫提高/2.selenium/1.无头浏览器的介绍.html">
            
                    
                    2.2.1 无头浏览器的介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="../../爬虫提高/2.selenium/2.selenium的基本使用.html">
            
                <a href="../../爬虫提高/2.selenium/2.selenium的基本使用.html">
            
                    
                    2.2.2 selenium的基本使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="../../爬虫提高/2.selenium/3.元素定位的方法.html">
            
                <a href="../../爬虫提高/2.selenium/3.元素定位的方法.html">
            
                    
                    2.2.3 selenium元素定位的方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="../../爬虫提高/2.selenium/4.selenium的其他方法.html">
            
                <a href="../../爬虫提高/2.selenium/4.selenium的其他方法.html">
            
                    
                    2.2.4 selenium的其他方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.5" data-path="../../爬虫提高/2.selenium/5.selenium案例.html">
            
                <a href="../../爬虫提高/2.selenium/5.selenium案例.html">
            
                    
                    2.2.5 selenium案例
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="../../爬虫提高/2.selenium/6.小结.html">
            
                <a href="../../爬虫提高/2.selenium/6.小结.html">
            
                    
                    2.2.6 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../爬虫提高/3.反扒以及解决方案/">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/">
            
                    
                    2.3 反爬以及解决方案
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="../../爬虫提高/3.反扒以及解决方案/1.常见的反扒手段和解决方法.html">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/1.常见的反扒手段和解决方法.html">
            
                    
                    2.3.1 常见反爬手段
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="../../爬虫提高/3.反扒以及解决方案/2.打码平台的使用.html">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/2.打码平台的使用.html">
            
                    
                    2.3.2 打码平台的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="../../爬虫提高/3.反扒以及解决方案/3.chrome在爬虫中的使用.html">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/3.chrome在爬虫中的使用.html">
            
                    
                    2.3.3 chrome在爬虫中的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="../../爬虫提高/3.反扒以及解决方案/4.JS的解析.html">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/4.JS的解析.html">
            
                    
                    2.3.4 JS的解析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.5" data-path="../../爬虫提高/3.反扒以及解决方案/5.小结.html">
            
                <a href="../../爬虫提高/3.反扒以及解决方案/5.小结.html">
            
                    
                    2.3.5 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../爬虫提高/4.MONGODB数据库/">
            
                <a href="../../爬虫提高/4.MONGODB数据库/">
            
                    
                    2.4 MONGODB数据库
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.4.1" data-path="../../爬虫提高/4.MONGODB数据库/1.mongodb的介绍和安装.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/1.mongodb的介绍和安装.html">
            
                    
                    2.4.1 mongodb的介绍和安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.2" data-path="../../爬虫提高/4.MONGODB数据库/2.mongodb的权限管理.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/2.mongodb的权限管理.html">
            
                    
                    2.4.2 mongodb的权限管理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.3" data-path="../../爬虫提高/4.MONGODB数据库/3.mongodb的基本使用.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/3.mongodb的基本使用.html">
            
                    
                    2.4.3 mongodb的入门使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.4" data-path="../../爬虫提高/4.MONGODB数据库/4.mongodb的聚合操作.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/4.mongodb的聚合操作.html">
            
                    
                    2.4.4 mongodb的聚合操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.5" data-path="../../爬虫提高/4.MONGODB数据库/5.mongodb的索引.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/5.mongodb的索引.html">
            
                    
                    2.4.5 mongodb的索引
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.6" data-path="../../爬虫提高/4.MONGODB数据库/6.mongodb的备份恢复与导入导出.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/6.mongodb的备份恢复与导入导出.html">
            
                    
                    2.4.6 mongodb的备份恢复与导入导出
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.7" data-path="../../爬虫提高/4.MONGODB数据库/7.mongodb和python的交互.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/7.mongodb和python的交互.html">
            
                    
                    2.4.7 mongodb和python交互
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.8" data-path="../../爬虫提高/4.MONGODB数据库/8.小结.html">
            
                <a href="../../爬虫提高/4.MONGODB数据库/8.小结.html">
            
                    
                    2.4.8 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../爬虫提高/5.scrapy/">
            
                <a href="../../爬虫提高/5.scrapy/">
            
                    
                    2.5 scrapy框架
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.5.1" data-path="../../爬虫提高/5.scrapy/1.scrapy的基础概念和流程.html">
            
                <a href="../../爬虫提高/5.scrapy/1.scrapy的基础概念和流程.html">
            
                    
                    2.5.1 scrapy的基础概念和流程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.2" data-path="../../爬虫提高/5.scrapy/2.scrapy的入门使用.html">
            
                <a href="../../爬虫提高/5.scrapy/2.scrapy的入门使用.html">
            
                    
                    2.5.2 scrapy的入门使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.3" data-path="../../爬虫提高/5.scrapy/3.scrapy发送翻页请求.html">
            
                <a href="../../爬虫提高/5.scrapy/3.scrapy发送翻页请求.html">
            
                    
                    2.5.3 scrapy发送翻页请求
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.4" data-path="../../爬虫提高/5.scrapy/4.scrapy的深入使用.html">
            
                <a href="../../爬虫提高/5.scrapy/4.scrapy的深入使用.html">
            
                    
                    2.5.4 scrapy的深入使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.5" data-path="../../爬虫提高/5.scrapy/5.crawlspider类的使用.html">
            
                <a href="../../爬虫提高/5.scrapy/5.crawlspider类的使用.html">
            
                    
                    2.5.5 crawlspider类的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.6" data-path="../../爬虫提高/5.scrapy/6.scrapy中间件.html">
            
                <a href="../../爬虫提高/5.scrapy/6.scrapy中间件.html">
            
                    
                    2.5.6 scarpy中间件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.7" data-path="../../爬虫提高/5.scrapy/7.scrapy模拟登陆.html">
            
                <a href="../../爬虫提高/5.scrapy/7.scrapy模拟登陆.html">
            
                    
                    2.5.7 scrapy模拟登陆
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5.8" data-path="../../爬虫提高/5.scrapy/9.小结.html">
            
                <a href="../../爬虫提高/5.scrapy/9.小结.html">
            
                    
                    2.5.8 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../../爬虫提高/6.scrapy_redis/">
            
                <a href="../../爬虫提高/6.scrapy_redis/">
            
                    
                    2.6 scrapy_redis
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.6.1" data-path="../../爬虫提高/6.scrapy_redis/1.scrapy_redis分布式原理.html">
            
                <a href="../../爬虫提高/6.scrapy_redis/1.scrapy_redis分布式原理.html">
            
                    
                    2.6.1 scrapy_redis分布式原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6.2" data-path="../../爬虫提高/6.scrapy_redis/2.scrapy_redis实现增量式爬虫.html">
            
                <a href="../../爬虫提高/6.scrapy_redis/2.scrapy_redis实现增量式爬虫.html">
            
                    
                    2.6.2 scrapy_redis实现增量式爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6.3" data-path="../../爬虫提高/6.scrapy_redis/3.scrapy_redis实现分布式爬虫.html">
            
                <a href="../../爬虫提高/6.scrapy_redis/3.scrapy_redis实现分布式爬虫.html">
            
                    
                    2.6.3 scrapy_redis实现分布式爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6.4" data-path="../../爬虫提高/6.scrapy_redis/4.scrapy_redis与scrapy的对比.html">
            
                <a href="../../爬虫提高/6.scrapy_redis/4.scrapy_redis与scrapy的对比.html">
            
                    
                    2.6.4 scrapy_redis与scrapy的对比
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6.5" data-path="../../爬虫提高/6.scrapy_redis/5.小结.html">
            
                <a href="../../爬虫提高/6.scrapy_redis/5.小结.html">
            
                    
                    2.6.5 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../../爬虫提高/7.爬虫的部署/">
            
                <a href="../../爬虫提高/7.爬虫的部署/">
            
                    
                    2.7 爬虫的部署
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.7.1" data-path="../../爬虫提高/7.爬虫的部署/1.scrapyd的使用.html">
            
                <a href="../../爬虫提高/7.爬虫的部署/1.scrapyd的使用.html">
            
                    
                    2.7.1 scrapyd的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7.2" data-path="../../爬虫提高/7.爬虫的部署/2.pycharm发布代码.html">
            
                <a href="../../爬虫提高/7.爬虫的部署/2.pycharm发布代码.html">
            
                    
                    2.7.2 pycharm发布代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7.3" data-path="../../爬虫提高/7.爬虫的部署/3.crontab实现定时任务.html">
            
                <a href="../../爬虫提高/7.爬虫的部署/3.crontab实现定时任务.html">
            
                    
                    2.7.3 crontab实现定时任务
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7.4" data-path="../../爬虫提高/7.爬虫的部署/4.小结.html">
            
                <a href="../../爬虫提高/7.爬虫的部署/4.小结.html">
            
                    
                    2.7.4 小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../">
            
                <a href="../">
            
                    
                    3 爬虫框架开发
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../1.爬虫框架开发分析/">
            
                <a href="../1.爬虫框架开发分析/">
            
                    
                    3.1 爬虫框架开发分析
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1.1" data-path="../1.爬虫框架开发分析/1.了解框架.html">
            
                <a href="../1.爬虫框架开发分析/1.了解框架.html">
            
                    
                    3.1.1 了解框架
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.2" data-path="../1.爬虫框架开发分析/2.框架设计思路分析.html">
            
                <a href="../1.爬虫框架开发分析/2.框架设计思路分析.html">
            
                    
                    3.1.2 框架设计思路分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.3" data-path="../1.爬虫框架开发分析/3.框架代码雏形结构.html">
            
                <a href="../1.爬虫框架开发分析/3.框架代码雏形结构.html">
            
                    
                    3.1.3 雏形代码结构
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../2.框架雏形实现/">
            
                <a href="../2.框架雏形实现/">
            
                    
                    3.2 框架雏形实现
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.2.1" data-path="../2.框架雏形实现/1.框架雏形--http模块和item模块.html">
            
                <a href="../2.框架雏形实现/1.框架雏形--http模块和item模块.html">
            
                    
                    3.2.1 http模块和item模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2.2" data-path="../2.框架雏形实现/2.框架雏形--核心模块.html">
            
                <a href="../2.框架雏形实现/2.框架雏形--核心模块.html">
            
                    
                    3.2.2 核心模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2.3" data-path="../2.框架雏形实现/3.框架安装.html">
            
                <a href="../2.框架雏形实现/3.框架安装.html">
            
                    
                    3.2.3 框架安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2.4" data-path="../2.框架雏形实现/4.框架运行--main.py.html">
            
                <a href="../2.框架雏形实现/4.框架运行--main.py.html">
            
                    
                    3.2.4 框架运行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2.5" data-path="../2.框架雏形实现/5.框架雏形--中间件模块.html">
            
                <a href="../2.框架雏形实现/5.框架雏形--中间件模块.html">
            
                    
                    3.2.5 中间件
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="./">
            
                <a href="./">
            
                    
                    3.3 框架功能完善
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.3.1" data-path="1.框架完善--日志模块使用.html">
            
                <a href="1.框架完善--日志模块使用.html">
            
                    
                    3.3.1 日志模块使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.2" data-path="2.框架完善--配置文件实现.html">
            
                <a href="2.框架完善--配置文件实现.html">
            
                    
                    3.3.2 配置文件实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.3" data-path="3.框架完善--多爬虫实现之一--多请求.html">
            
                <a href="3.框架完善--多爬虫实现之一--多请求.html">
            
                    
                    3.3.3 多请求实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.4" data-path="4.框架完善--多爬虫实现之二--多个解析函数.html">
            
                <a href="4.框架完善--多爬虫实现之二--多个解析函数.html">
            
                    
                    3.3.4 多个解析函数实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.5" data-path="5.框架完善--多爬虫实现之三--多爬虫文件.html">
            
                <a href="5.框架完善--多爬虫实现之三--多爬虫文件.html">
            
                    
                    3.3.5 多爬虫文件实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.6" data-path="6.框架完善--实现多个管道.html">
            
                <a href="6.框架完善--实现多个管道.html">
            
                    
                    3.3.6 实现多个管道
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.7" data-path="7.框架完善--实现多个中间件.html">
            
                <a href="7.框架完善--实现多个中间件.html">
            
                    
                    3.3.7 实现多个中间件
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.3.8" data-path="8.框架完善--实现动态模块导入.html">
            
                <a href="8.框架完善--实现动态模块导入.html">
            
                    
                    3.3.8 实现动态模块导入
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.9" data-path="9.框架完善--实现请求去重.html">
            
                <a href="9.框架完善--实现请求去重.html">
            
                    
                    3.3.9 实现请求去重
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.10" data-path="10.框架完善--使用线程池实现异步以及并发控制.html">
            
                <a href="10.框架完善--使用线程池实现异步以及并发控制.html">
            
                    
                    3.3.10 使用线程池实现异步以及并发控制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3.11" data-path="11.框架完善--使用协程池实现异步以及并发控制.html">
            
                <a href="11.框架完善--使用协程池实现异步以及并发控制.html">
            
                    
                    3.3.11 使用协程池实现异步以及并发控制
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../5.框架功能升级/">
            
                <a href="../5.框架功能升级/">
            
                    
                    3.4 框架功能升级
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.4.1" data-path="../5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
            
                <a href="../5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
            
                    
                    3.4.1 分布式爬虫设计原理及其实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4.2" data-path="../5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
            
                <a href="../5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
            
                    
                    3.4.2 增量爬虫设计原理及其实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4.3" data-path="../5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
            
                <a href="../5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
            
                    
                    3.4.3 断点续爬设计原理及其实现
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../6.项目实战/">
            
                <a href="../6.项目实战/">
            
                    
                    3.5 项目实战
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.5.1" data-path="../6.项目实战/1.案例1-scrapy_plus实现腾讯招聘爬虫.html">
            
                <a href="../6.项目实战/1.案例1-scrapy_plus实现腾讯招聘爬虫.html">
            
                    
                    3.5.1 scrapy_plus实现腾讯招聘爬虫
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.2" data-path="../6.项目实战/2.案例2-scrapy_plus实现新浪新闻爬虫.html">
            
                <a href="../6.项目实战/2.案例2-scrapy_plus实现新浪新闻爬虫.html">
            
                    
                    3.5.2 scrapy_plus实现新浪滚动新闻爬虫
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../../扩展阅读/">
            
                <a href="../../扩展阅读/">
            
                    
                    4 扩展阅读
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../../扩展阅读/ascii和unicode以及utf-8.html">
            
                <a href="../../扩展阅读/ascii和unicode以及utf-8.html">
            
                    
                    4.1 ascii、unicode和utf-8的起源
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../../扩展阅读/charles使用指南.html">
            
                <a href="../../扩展阅读/charles使用指南.html">
            
                    
                    4.2 charles使用指南
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../../扩展阅读/urllib中Handler处理器和自定义Opener.html">
            
                <a href="../../扩展阅读/urllib中Handler处理器和自定义Opener.html">
            
                    
                    4.3 urlib的扩展
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../../扩展阅读/redis-manger-desktop.html">
            
                <a href="../../扩展阅读/redis-manger-desktop.html">
            
                    
                    4.4 redis-desktop-manger的介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="../../扩展阅读/代理ip检测.html">
            
                <a href="../../扩展阅读/代理ip检测.html">
            
                    
                    4.5 代理ip检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="../../扩展阅读/selenium深入拓展.html">
            
                <a href="../../扩展阅读/selenium深入拓展.html">
            
                    
                    4.6 selenium深入拓展
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.7" data-path="../../扩展阅读/docker简单使用.html">
            
                <a href="../../扩展阅读/docker简单使用.html">
            
                    
                    4.7 docker在爬虫中的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.8" data-path="../../扩展阅读/appium介绍.html">
            
                <a href="../../扩展阅读/appium介绍.html">
            
                    
                    4.8 appium介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.9" data-path="../../扩展阅读/pywin32介绍.html">
            
                <a href="../../扩展阅读/pywin32介绍.html">
            
                    
                    4.9 pywin32介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.10" data-path="../../扩展阅读/百度翻译sign值获取.html">
            
                <a href="../../扩展阅读/百度翻译sign值获取.html">
            
                    
                    4.10 百度翻译获取sign值
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.11" data-path="../../扩展阅读/scrapy中ImagePipeline的使用.html">
            
                <a href="../../扩展阅读/scrapy中ImagePipeline的使用.html">
            
                    
                    4.11 scrapy中ImagePipeline的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.12" data-path="../../扩展阅读/sanic、quart类Flask的异步框架介绍.html">
            
                <a href="../../扩展阅读/sanic、quart类Flask的异步框架介绍.html">
            
                    
                    4.12 sanic、quart类Flask的异步框架介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.13" data-path="../../扩展阅读/了解其他网络请求模块.html">
            
                <a href="../../扩展阅读/了解其他网络请求模块.html">
            
                    
                    4.13 了解其他网络请求模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.14" data-path="../../扩展阅读/通过Fiddler进行手机抓包.html">
            
                <a href="../../扩展阅读/通过Fiddler进行手机抓包.html">
            
                    
                    4.14 通过Fiddler进行手机抓包
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.15" data-path="../../扩展阅读/Fiddler抓取https的设置.html">
            
                <a href="../../扩展阅读/Fiddler抓取https的设置.html">
            
                    
                    4.15 Fiddler抓取https的设置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.16" data-path="../../扩展阅读/12306.html">
            
                <a href="../../扩展阅读/12306.html">
            
                    
                    4.16 关于12306抢票
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.17" data-path="../../扩展阅读/svn和git的使用.html">
            
                <a href="../../扩展阅读/svn和git的使用.html">
            
                    
                    4.17 svn和git的使用
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >3.3.8 实现动态模块导入</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x6A21;&#x5757;">&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x6A21;&#x5757;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;">&#x5B66;&#x4E60;&#x76EE;&#x6807;</h5>
<ol>
<li>&#x638C;&#x63E1;&#x6A21;&#x5757;&#x7684;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x5B8C;&#x6210;&#x5BF9;&#x73B0;&#x6709;&#x4EE3;&#x7801;&#x7684;&#x91CD;&#x6784;</li>
</ol>
<hr>
<h3 id="1-&#x76EE;&#x524D;&#x4EE3;&#x7801;&#x5B58;&#x5728;&#x7684;&#x95EE;&#x9898;">1 &#x76EE;&#x524D;&#x4EE3;&#x7801;&#x5B58;&#x5728;&#x7684;&#x95EE;&#x9898;</h3>
<p>&#x901A;&#x8FC7;&#x524D;&#x9762;&#x7684;&#x4EE3;&#x7801;&#x7F16;&#x5199;&#xFF0C;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x80FD;&#x591F;&#x5B8C;&#x6210;&#x5927;&#x90E8;&#x5206;&#x7684;&#x4EFB;&#x52A1;&#xFF0C;&#x4F46;&#x662F;&#x5728;<code>main.py</code> &#x4E2D;&#x7684;&#x4EE3;&#x7801;&#x975E;&#x5E38;&#x81C3;&#x80BF;&#xFF0C;&#x5BF9;&#x5E94;&#x7684;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x518D;<code>settings.py</code> &#x914D;&#x7F6E;&#x54EA;&#x4E9B;&#x722C;&#x866B;&#xFF0C;&#x7BA1;&#x9053;&#xFF0C;&#x4E2D;&#x95F4;&#x4EF6;&#x9700;&#x8981;&#x5F00;&#x542F;&#xFF0C;&#x80FD;&#x591F;&#x8BA9;&#x6574;&#x4E2A;&#x4EE3;&#x7801;&#x7684;&#x903B;&#x8F91;&#x66F4;&#x52A0;&#x6E05;&#x6670;</p>
<h3 id="2--&#x6A21;&#x5757;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x7684;&#x65B9;&#x6CD5;">2  &#x6A21;&#x5757;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x7684;&#x65B9;&#x6CD5;</h3>
<p>&#x5229;&#x7528;<code>importlib.import_modle</code>&#x80FD;&#x591F;&#x4F20;&#x5165;&#x6A21;&#x5757;&#x7684;&#x8DEF;&#x5F84;&#xFF0C;&#x5373;&#x53EF;&#x5373;&#x53EF;&#x5B9E;&#x73B0;&#x6839;&#x636E;&#x6A21;&#x5757;&#x7684;&#x4F4D;&#x7F6E;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5BFC;&#x5165;&#x8BE5;&#x6A21;&#x5757;&#x7684;&#x529F;&#x80FD;</p>
<h3 id="3-&#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;spider&#xFF0C;middlewares">3 &#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;SPIDER&#xFF0C;MIDDLEWARES</h3>
<h5 id="31-&#x5229;&#x7528;&#x5728;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x8BBE;&#x7F6E;&#x9700;&#x8981;&#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x7C7B;&#x3001;&#x7BA1;&#x9053;&#x7C7B;&#x3001;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;">3.1 &#x5229;&#x7528;&#x5728;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x8BBE;&#x7F6E;&#x9700;&#x8981;&#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x7C7B;&#x3001;&#x7BA1;&#x9053;&#x7C7B;&#x3001;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;</h5>
<p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/settings.py</p>
<pre class="language-"><code class="lang-pyton"># &#x9879;&#x76EE;&#x4E2D;&#x7684;settings.py

......

# &#x589E;&#x52A0;&#x4EE5;&#x4E0B;&#x4FE1;&#x606F;&#xFF1A;
# &#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x7C7B;
SPIDERS = [
    &apos;spiders.baidu.BaiduSpider&apos;,
    &apos;spiders.douban.DoubanSpider&apos;
]

# &#x542F;&#x7528;&#x7684;&#x7BA1;&#x9053;&#x7C7B;
PIPELINES = [
    &apos;pipelines.BaiduPipeline&apos;,
    &apos;pipelines.DoubanPipeline&apos;
]

# &#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
SPIDER_MIDDLEWARES = []

# &#x542F;&#x7528;&#x7684;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
DOWNLOADER_MIDDLEWARES = []
</code></pre>
<h5 id="32-&#x5229;&#x7528;importlib&#x6A21;&#x5757;&#xFF0C;&#x5728;&#x5F15;&#x64CE;&#x4E2D;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;">3.2 &#x5229;&#x7528;importlib&#x6A21;&#x5757;&#xFF0C;&#x5728;&#x5F15;&#x64CE;&#x4E2D;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;</h5>
<p>scrapy_plus/core/engine.py</p>
<pre class="language-"><code class="lang-python"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">import</span> importlib
<span class="token keyword">from</span> scrapy_plus<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>settings <span class="token keyword">import</span> SPIDERS<span class="token punctuation">,</span> PIPELINES<span class="token punctuation">,</span> SPIDER_MIDDLEWARES<span class="token punctuation">,</span> DOWNLOADER_MIDDLEWARES

<span class="token keyword">class</span> <span class="token class-name">Engine</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x5B8C;&#x6210;&#x5BF9;&#x5F15;&#x64CE;&#x6A21;&#x5757;&#x7684;&#x5C01;&#x88C5;&apos;&apos;&apos;</span>

<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>

    self<span class="token punctuation">.</span>spiders <span class="token operator">=</span> self<span class="token punctuation">.</span>_auto_import_instances<span class="token punctuation">(</span>SPIDERS<span class="token punctuation">,</span>isspider<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &#x63A5;&#x6536;&#x722C;&#x866B;&#x5B57;&#x5178; # &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>
    self<span class="token punctuation">.</span>scheduler <span class="token operator">=</span> Scheduler<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x521D;&#x59CB;&#x5316;&#x8C03;&#x5EA6;&#x5668;&#x5BF9;&#x8C61;</span>
    self<span class="token punctuation">.</span>downloader <span class="token operator">=</span> Downloader<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x521D;&#x59CB;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x5BF9;&#x8C61;</span>

    <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>
    self<span class="token punctuation">.</span>pipelines <span class="token operator">=</span> self<span class="token punctuation">.</span>_auto_import_instances<span class="token punctuation">(</span>PIPELINES<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># &#x7BA1;&#x9053;</span>
    self<span class="token punctuation">.</span>spider_mids <span class="token operator">=</span> self<span class="token punctuation">.</span>_auto_import_instances<span class="token punctuation">(</span>SPIDER_MIDDLEWARES<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># &#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;</span>
    self<span class="token punctuation">.</span>downloader_mids <span class="token operator">=</span> self<span class="token punctuation">.</span>_auto_import_instances<span class="token punctuation">(</span>DOWNLOADER_MIDDLEWARES<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># &#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</span>

    self<span class="token punctuation">.</span>total_request_nums <span class="token operator">=</span> <span class="token number">0</span>
    self<span class="token punctuation">.</span>total_response_nums <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;&#x51FD;&#x6570;    </span>
<span class="token keyword">def</span> <span class="token function">_auto_import_instances</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> isspider<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x901A;&#x8FC7;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF0C;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x7C7B;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;
    path: &#x8868;&#x793A;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x914D;&#x7F6E;&#x7684;&#x5BFC;&#x5165;&#x7C7B;&#x7684;&#x8DEF;&#x5F84;
    isspider: &#x7531;&#x4E8E;&#x722C;&#x866B;&#x9700;&#x8981;&#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x5B57;&#x5178;&#xFF0C;&#x56E0;&#x6B64;&#x5BF9;&#x5176;&#x505A;&#x5BF9;&#x5E94;&#x7684;&#x5224;&#x65AD;&#x548C;&#x5904;&#x7406;
    &apos;&apos;&apos;</span>
    instances <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token keyword">if</span> isspider <span class="token keyword">else</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> path<span class="token punctuation">:</span>
        module_name <span class="token operator">=</span> p<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">&quot;.&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># &#x53D6;&#x51FA;&#x6A21;&#x5757;&#x540D;&#x79F0;</span>
        cls_name <span class="token operator">=</span> p<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">&quot;.&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># &#x53D6;&#x51FA;&#x7C7B;&#x540D;&#x79F0;</span>
        ret <span class="token operator">=</span> importlib<span class="token punctuation">.</span>import_module<span class="token punctuation">(</span>module_name<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x722C;&#x866B;&#x6A21;&#x5757;</span>
        cls <span class="token operator">=</span> getattr<span class="token punctuation">(</span>ret<span class="token punctuation">,</span> cls_name<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &#x6839;&#x636E;&#x7C7B;&#x540D;&#x79F0;&#x83B7;&#x53D6;&#x7C7B;&#x5BF9;&#x8C61;</span>

        <span class="token keyword">if</span> isspider<span class="token punctuation">:</span>
            instances<span class="token punctuation">[</span>cls<span class="token punctuation">.</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &#x7EC4;&#x88C5;&#x6210;&#x722C;&#x866B;&#x5B57;&#x5178;{spider_name:spider(),}</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            instances<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cls<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &#x5B9E;&#x4F8B;&#x5316;&#x7C7B;&#x5BF9;&#x8C61;</span>
            <span class="token comment" spellcheck="true"># &#x628A;&#x7BA1;&#x9053;&#x4E2D;&#x95F4;&#x4EF6;&#x5206;&#x522B;&#x7EC4;&#x88C5;&#x6210; &#x7BA1;&#x9053;&#x5217;&#x8868;=[&#x7BA1;&#x9053;&#x7C7B;1(),&#x7BA1;&#x9053;&#x7C7B;2()] / &#x4E2D;&#x95F4;&#x4EF6;&#x5217;&#x8868; = [&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;1(),&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;2()]</span>
    <span class="token keyword">return</span> instances  <span class="token comment" spellcheck="true"># &#x8FD4;&#x56DE;&#x7C7B;&#x5BF9;&#x8C61;&#x5B57;&#x5178;&#x6216;&#x5217;&#x8868;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<h5 id="33-&#x5173;&#x4E8E;rsplit">3.3 &#x5173;&#x4E8E;rsplit()</h5>
<p>rsplit() &#x65B9;&#x6CD5;&#x901A;&#x8FC7;&#x6307;&#x5B9A;&#x5206;&#x9694;&#x7B26;&#x5BF9;&#x5B57;&#x7B26;&#x4E32;&#x8FDB;&#x884C;&#x5206;&#x5272;&#x5E76;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5206;&#x5272;&#x540E;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x5217;&#x8868;&#xFF0C;&#x9ED8;&#x8BA4;&#x5206;&#x9694;&#x7B26;&#x4E3A;&#x6240;&#x6709;&#x7A7A;&#x5B57;&#x7B26;&#xFF0C;&#x5305;&#x62EC;&#x7A7A;&#x683C;&#x3001;&#x6362;&#x884C;(\n)&#x3001;&#x5236;&#x8868;&#x7B26;(\t)&#x7B49;&#x3002;&#x7C7B;&#x4F3C;&#x4E8E; split() &#x65B9;&#x6CD5;&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;&#x662F;&#x4ECE;&#x5B57;&#x7B26;&#x4E32;&#x6700;&#x540E;&#x9762;&#x5F00;&#x59CB;&#x5206;&#x5272;&#x3002;</p>
<pre class="language-"><code class="lang-python">s <span class="token operator">=</span> <span class="token string">&quot;this is string example....wow!!!&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">&apos;i&apos;</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">&apos;w&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># &#x4EE5;&#x4E0A;&#x5B9E;&#x4F8B;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#xFF1A;</span>
<span class="token comment" spellcheck="true"># [&apos;this&apos;, &apos;is&apos;, &apos;string&apos;, &apos;example....wow!!!&apos;]</span>
<span class="token comment" spellcheck="true"># [&apos;this is str&apos;, &apos;ng example....wow!!!&apos;]</span>
<span class="token comment" spellcheck="true"># [&apos;this is string example....&apos;, &apos;o&apos;, &apos;!!!&apos;]</span>
</code></pre>
<h4 id="34-&#x4FEE;&#x6539;&#x6846;&#x67B6;&#x4E2D;&#x7684;&#x9ED8;&#x8BA4;&#x914D;&#x7F6E;&#x6587;&#x4EF6;">3.4 &#x4FEE;&#x6539;&#x6846;&#x67B6;&#x4E2D;&#x7684;&#x9ED8;&#x8BA4;&#x914D;&#x7F6E;&#x6587;&#x4EF6;</h4>
<pre class="language-"><code class="lang-python">scrapy_plus<span class="token operator">/</span>conf<span class="token operator">/</span>default_settings<span class="token punctuation">.</span>py

<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token comment" spellcheck="true"># &#x65B0;&#x589E;</span>
<span class="token comment" spellcheck="true"># &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x7BA1;&#x9053;&#x7C7B;</span>
PIPELINES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;</span>
SPIDER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;</span>
DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
</code></pre>
<h3 id="4-&#x4FEE;&#x6539;mainpy">4 &#x4FEE;&#x6539;<code>main.py</code></h3>
<p>&#x8FD9;&#x6837;main.py&#x5C31;&#x4E0D;&#x7528;&#x518D;&#x5BFC;&#x5165;&#x5E76;&#x4F20;&#x5165;&#x90A3;&#x4E48;&#x591A;&#x5BF9;&#x8C61;&#x4E86;&#xFF1A;</p>
<pre class="language-"><code class="lang-Python"># project_dir/main.py
from scrapy_plus.core.engine import Engine    # &#x5BFC;&#x5165;&#x5F15;&#x64CE;

if __name__ == &apos;__main__&apos;:
    engine = Engine()  # &#x521B;&#x5EFA;&#x5F15;&#x64CE;&#x5BF9;&#x8C61;
    engine.start()    # &#x542F;&#x52A8;&#x5F15;&#x64CE;
</code></pre>
<hr>
<h3 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h3>
<ol>
<li>&#x638C;&#x63E1;<code>importlib.import_module</code>&#x65B9;&#x6CD5;&#x4F7F;&#x7528;</li>
<li>&#x5B8C;&#x6210;&#x4EE3;&#x7801;&#x7684;&#x91CD;&#x6784;&#xFF0C;&#x5B9E;&#x73B0;&#x901A;&#x8FC7;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x5BFC;&#x5165;&#x6A21;&#x5757;</li>
</ol>
<hr>
<h3 id="&#x672C;&#x5C0F;&#x7ED3;&#x6D89;&#x53CA;&#x4FEE;&#x6539;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;">&#x672C;&#x5C0F;&#x7ED3;&#x6D89;&#x53CA;&#x4FEE;&#x6539;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;</h3>
<p>scrapy_plus/core/engine.py</p>
<pre class="language-"><code>&apos;&apos;&apos;&#x5F15;&#x64CE;&#x7EC4;&#x4EF6;&apos;&apos;&apos;
from scrapy_plus.http.request import Request    # &#x5BFC;&#x5165;Request&#x5BF9;&#x8C61;

from .scheduler import Scheduler
from .downloader import Downloader
from .pipeline import Pipeline
from .spider import Spider

from scrapy_plus.middlewares.spider_middlewares import SpiderMiddleware
from scrapy_plus.middlewares.downloader_middlewares import DownloaderMiddleware

import time
from datetime import datetime
from scrapy_plus.utils.log import logger    # &#x5BFC;&#x5165;logger

import importlib
from scrapy_plus.conf.settings import SPIDERS, PIPELINES, SPIDER_MIDDLEWARES, DOWNLOADER_MIDDLEWARES


class Engine(object):
    &apos;&apos;&apos;
    a. &#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x6574;&#x4E2A;&#x7684;&#x7A0B;&#x5E8F;&#x7684;&#x5165;&#x53E3;
    b. &#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)
    &apos;&apos;&apos;

    def __init__(self):
        self.spiders = self._auto_import_instances(SPIDERS,isspider=True)   # &#x63A5;&#x6536;&#x722C;&#x866B;&#x5B57;&#x5178;
        self.scheduler = Scheduler()    # &#x521D;&#x59CB;&#x5316;&#x8C03;&#x5EA6;&#x5668;&#x5BF9;&#x8C61;
        self.downloader = Downloader()    # &#x521D;&#x59CB;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x5BF9;&#x8C61;

        self.pipelines = self._auto_import_instances(PIPELINES) # &#x7BA1;&#x9053;
        self.spider_mids = self._auto_import_instances(SPIDER_MIDDLEWARES) # &#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;
        self.downloader_mids = self._auto_import_instances(DOWNLOADER_MIDDLEWARES) # &#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;

        self.total_request_nums = 0
        self.total_response_nums = 0

    def _auto_import_instances(self, path=[], isspider=False):
        &apos;&apos;&apos;&#x901A;&#x8FC7;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF0C;&#x52A8;&#x6001;&#x5BFC;&#x5165;&#x7C7B;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;
        path: &#x8868;&#x793A;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x914D;&#x7F6E;&#x7684;&#x5BFC;&#x5165;&#x7C7B;&#x7684;&#x8DEF;&#x5F84;
        isspider: &#x7531;&#x4E8E;&#x722C;&#x866B;&#x9700;&#x8981;&#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x5B57;&#x5178;&#xFF0C;&#x56E0;&#x6B64;&#x5BF9;&#x5176;&#x505A;&#x5BF9;&#x5E94;&#x7684;&#x5224;&#x65AD;&#x548C;&#x5904;&#x7406;
        &apos;&apos;&apos;
        instances = {} if isspider else []
        for p in path:
            module_name = p.rsplit(&quot;.&quot;, 1)[0]  # &#x53D6;&#x51FA;&#x6A21;&#x5757;&#x540D;&#x79F0;
            cls_name = p.rsplit(&quot;.&quot;, 1)[1]  # &#x53D6;&#x51FA;&#x7C7B;&#x540D;&#x79F0;
            ret = importlib.import_module(module_name)  # &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x722C;&#x866B;&#x6A21;&#x5757;
            cls = getattr(ret, cls_name)  # &#x6839;&#x636E;&#x7C7B;&#x540D;&#x79F0;&#x83B7;&#x53D6;&#x7C7B;&#x5BF9;&#x8C61;

            if isspider:
                instances[cls.name] = cls()  # &#x7EC4;&#x88C5;&#x6210;&#x722C;&#x866B;&#x5B57;&#x5178;{spider_name:spider(),}
            else:
                instances.append(cls())  # &#x5B9E;&#x4F8B;&#x5316;&#x7C7B;&#x5BF9;&#x8C61;
                # &#x628A;&#x7BA1;&#x9053;&#x4E2D;&#x95F4;&#x4EF6;&#x5206;&#x522B;&#x7EC4;&#x88C5;&#x6210; &#x7BA1;&#x9053;&#x5217;&#x8868;=[&#x7BA1;&#x9053;&#x7C7B;1(),&#x7BA1;&#x9053;&#x7C7B;2()] / &#x4E2D;&#x95F4;&#x4EF6;&#x5217;&#x8868; = [&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;1(),&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;2()]
        return instances  # &#x8FD4;&#x56DE;&#x7C7B;&#x5BF9;&#x8C61;&#x5B57;&#x5178;&#x6216;&#x5217;&#x8868;

    def start(self):
        &apos;&apos;&apos;&#x542F;&#x52A8;&#x6574;&#x4E2A;&#x5F15;&#x64CE;&apos;&apos;&apos;
        start_time = datetime.now()  # &#x8D77;&#x59CB;&#x65F6;&#x95F4;
        logger.info(&quot;&#x5F00;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF1A;%s&quot; % start_time)  # &#x4F7F;&#x7528;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x8D77;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;
        self._start_engine()
        end_time = datetime.now()
        logger.info(&quot;&#x722C;&#x866B;&#x7ED3;&#x675F;&#xFF1A;{}&quot;.format(end_time))
        logger.info(&quot;&#x722C;&#x866B;&#x4E00;&#x5171;&#x8FD0;&#x884C;&#xFF1A;{}&#x79D2;&quot;.format((end_time-start_time).total_seconds()))
        logger.info(&quot;&#x603B;&#x7684;&#x8BF7;&#x6C42;&#x6570;&#x91CF;:{}&quot;.format(self.total_request_nums))
        logger.info(&quot;&#x603B;&#x7684;&#x54CD;&#x5E94;&#x6570;&#x91CF;:{}&quot;.format(self.total_response_nums))

    def _start_request(self):
        for spider_name, spider in self.spiders.items():
            for start_request in spider.start_requests():
                #1. &#x5BF9;start_request&#x8FDB;&#x8FC7;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x8FDB;&#x884C;&#x5904;&#x7406;
                for spider_mid in self.spider_mids:
                    start_request = spider_mid.process_request(start_request)

                # &#x4E3A;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7ED1;&#x5B9A;&#x5B83;&#x6240;&#x5C5E;&#x7684;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;
                start_request.spider_name = spider_name

                #2. &#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;add_request&#x65B9;&#x6CD5;&#xFF0C;&#x6DFB;&#x52A0;request&#x5BF9;&#x8C61;&#x5230;&#x8C03;&#x5EA6;&#x5668;&#x4E2D;
                self.scheduler.add_request(start_request)
                #&#x8BF7;&#x6C42;&#x6570;+1
                self.total_request_nums += 1

    def _execute_request_response_item(self):
        &apos;&apos;&apos;&#x6839;&#x636E;&#x8BF7;&#x6C42;&#x3001;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x3001;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x3001;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x7ED3;&#x679C;&apos;&apos;&apos;
        #3. &#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;get_request&#x65B9;&#x6CD5;&#xFF0C;&#x83B7;&#x53D6;request&#x5BF9;&#x8C61;
        request = self.scheduler.get_request()
        if request is None: #&#x5982;&#x679C;&#x6CA1;&#x6709;&#x83B7;&#x53D6;&#x5230;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;
            return

        #request&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_request&#x8FDB;&#x884C;&#x5904;&#x7406;
        for downloader_mid in self.downloader_mids:
            request = downloader_mid.process_request(request)

        #4. &#x8C03;&#x7528;&#x4E0B;&#x8F7D;&#x5668;&#x7684;get_response&#x65B9;&#x6CD5;&#xFF0C;&#x83B7;&#x53D6;&#x54CD;&#x5E94;
        response = self.downloader.get_response(request)

        response.meta = request.meta

        #response&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x8FDB;&#x884C;&#x5904;&#x7406;
        for downloader_mid in self.downloader_mids:
            response = downloader_mid.process_response(response)

        #response&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x8FDB;&#x884C;&#x5904;&#x7406;
        for spider_mid in self.spider_mids:
            response = spider_mid.process_response(response)

        # &#x6839;&#x636E;request&#x7684;spider_name&#x5C5E;&#x6027;&#xFF0C;&#x83B7;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x722C;&#x866B;&#x5BF9;&#x8C61;
        spider = self.spiders[request.spider_name]
        # parse&#x65B9;&#x6CD5;
        parse = getattr(spider, request.parse)  # getattr(&#x7C7B;, &#x7C7B;&#x4E2D;&#x65B9;&#x6CD5;&#x540D;&#x7684;&#x5B57;&#x7B26;&#x4E32;) = &#x7C7B;&#x65B9;&#x6CD5;&#x5BF9;&#x8C61;

        #5. &#x8C03;&#x7528;&#x722C;&#x866B;&#x7684;parse&#x65B9;&#x6CD5;&#xFF0C;&#x5904;&#x7406;&#x54CD;&#x5E94;
        for result in parse(response):
            #6.&#x5224;&#x65AD;&#x7ED3;&#x679C;&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x5982;&#x679C;&#x662F;request&#xFF0C;&#x91CD;&#x65B0;&#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;add_request&#x65B9;&#x6CD5;
            if isinstance(result,Request):
                #&#x5728;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x5F97;&#x5230;request&#x5BF9;&#x8C61;&#x4E4B;&#x540E;&#xFF0C;&#x4F7F;&#x7528;process_request&#x8FDB;&#x884C;&#x5904;&#x7406;

                for spider_mid in self.spider_mids:
                    result = spider_mid.process_request(result)

                # &#x7ED9;request&#x5BF9;&#x8C61;&#x589E;&#x52A0;&#x4E00;&#x4E2A;spider_name&#x5C5E;&#x6027;
                result.spider_name = request.spider_name

                self.scheduler.add_request(result)
                self.total_request_nums += 1
            #7&#x5982;&#x679C;&#x4E0D;&#x662F;&#xFF0C;&#x8C03;&#x7528;pipeline&#x7684;process_item&#x65B9;&#x6CD5;&#x5904;&#x7406;&#x7ED3;&#x679C;
            else:
                # &#x5C31;&#x901A;&#x8FC7;process_item()&#x4F20;&#x9012;&#x6570;&#x636E;&#x7ED9;&#x7BA1;&#x9053;
                for pipeline in self.pipelines:
                    pipeline.process_item(result, spider)

        self.total_response_nums += 1

    def _start_engine(self):
        &apos;&apos;&apos;
        &#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;&#x5F15;&#x64CE;&#x7684;&#x7EC6;&#x8282;
        :return:
        &apos;&apos;&apos;
        self._start_request()
        while True:
            time.sleep(0.001)
            self._execute_request_response_item()
            if self.total_response_nums&gt;= self.total_request_nums:
                break
</code></pre><p>scrapy_plus/default_settings.py</p>
<pre class="language-"><code>import logging

# &#x9ED8;&#x8BA4;&#x7684;&#x65E5;&#x5FD7;&#x914D;&#x7F6E;
DEFAULT_LOG_LEVEL = logging.INFO    # &#x9ED8;&#x8BA4;&#x7B49;&#x7EA7;
DEFAULT_LOG_FMT = &apos;%(asctime)s %(filename)s[line:%(lineno)d] \
                  %(levelname)s: %(message)s&apos;   # &#x9ED8;&#x8BA4;&#x65E5;&#x5FD7;&#x683C;&#x5F0F;
DEFUALT_LOG_DATEFMT = &apos;%Y-%m-%d %H:%M:%S&apos;  # &#x9ED8;&#x8BA4;&#x65F6;&#x95F4;&#x683C;&#x5F0F;
DEFAULT_LOG_FILENAME = &apos;log.log&apos;    # &#x9ED8;&#x8BA4;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x540D;&#x79F0;

# &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x7BA1;&#x9053;&#x7C7B;
PIPELINES = []

# &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
SPIDER_MIDDLEWARES = []

# &#x542F;&#x7528;&#x7684;&#x9ED8;&#x8BA4;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
DOWNLOADER_MIDDLEWARES = []
</code></pre><p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/main.py</p>
<pre class="language-"><code>from scrapy_plus.core.engine import Engine    # &#x5BFC;&#x5165;&#x5F15;&#x64CE;

if __name__ == &apos;__main__&apos;:
    engine = Engine()  # &#x521B;&#x5EFA;&#x5F15;&#x64CE;&#x5BF9;&#x8C61;
    engine.start()    # &#x542F;&#x52A8;&#x5F15;&#x64CE;
</code></pre><p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/settings.py</p>
<pre class="language-"><code># &#x4FEE;&#x6539;&#x9ED8;&#x8BA4;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x540D;&#x79F0;
DEFAULT_LOG_FILENAME = &apos;&#x65E5;&#x5FD7;.log&apos;    # &#x9ED8;&#x8BA4;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x540D;&#x79F0;

# &#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x7C7B;
SPIDERS = [
    &apos;spiders.baidu.BaiduSpider&apos;,
    &apos;spiders.douban.DoubanSpider&apos;
]

# &#x542F;&#x7528;&#x7684;&#x7BA1;&#x9053;&#x7C7B;
PIPELINES = [
    &apos;pipelines.BaiduPipeline&apos;,
    &apos;pipelines.DoubanPipeline&apos;
]

# &#x542F;&#x7528;&#x7684;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
SPIDER_MIDDLEWARES = []

# &#x542F;&#x7528;&#x7684;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7C7B;
DOWNLOADER_MIDDLEWARES = []
</code></pre>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="7.框架完善--实现多个中间件.html" class="navigation navigation-prev " aria-label="Previous page: 3.3.7 实现多个中间件">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="9.框架完善--实现请求去重.html" class="navigation navigation-next " aria-label="Next page: 3.3.9 实现请求去重">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"3.3.8 实现动态模块导入","level":"1.4.3.8","depth":3,"next":{"title":"3.3.9 实现请求去重","level":"1.4.3.9","depth":3,"path":"爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.md","ref":"./爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.md","articles":[]},"previous":{"title":"3.3.7 实现多个中间件","level":"1.4.3.7","depth":3,"path":"爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.md","ref":"./爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["emphasize","prism","-highlight","expandable-chapters-small","book-summary-scroll-position-saver","livereload"],"pluginsConfig":{"prism":{"css":["prismjs/themes/prism-solarizedlight.css"]},"emphasize":{},"livereload":{},"book-summary-scroll-position-saver":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"expandable-chapters-small":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.md","mtime":"2018-07-04T11:45:49.361Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-09-19T15:48:21.144Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-book-summary-scroll-position-saver/book-summary-scroll-position-saver.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

